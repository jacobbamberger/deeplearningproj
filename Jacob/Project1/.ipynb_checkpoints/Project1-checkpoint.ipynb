{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c2c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import prologue\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4007fbf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 14, 14])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 3])\n"
     ]
    }
   ],
   "source": [
    "#just plotting a pair\n",
    "train_img, train_target, train_classes, test_img, test_target, test_classes = prologue.generate_pair_sets(1)\n",
    "# plot the first training sample pair\n",
    "print(train_img.shape)\n",
    "fig = plt.figure\n",
    "plt.imshow(train_img[0, 0], cmap='gray')\n",
    "plt.show() \n",
    "plt.imshow(train_img[0, 1], cmap='gray')\n",
    "plt.show() \n",
    "print(train_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "158e1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following is training two models independently, \n",
    "# one per pair of digit, and on top of that to train another one \n",
    "# that predicts the class\n",
    "\n",
    "######################################################################\n",
    "\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32,\n",
    "                               kernel_size = 4,\n",
    "                               padding = (4 - 1) // 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 128,\n",
    "                               kernel_size = 4)\n",
    "                               #padding = (4 - 1) // 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # self.fc1 = nn.Linear( 32 , 10)\n",
    "\n",
    "        #these are 4x4x8 + 4x4x8x32 +10x32 = 4 544 params (does tachnorm have param..?)\n",
    "        \n",
    "        #self.conv3 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        #self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear( 128 , 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool2d(self.conv1(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        x = self.bn1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2(x)\n",
    "        x = F.max_pool2d(self.conv2(x), kernel_size=2)\n",
    "        x = self.bn2(x)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(x)\n",
    "        #x = F.max_pool2d(self.conv3(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        #x = self.bn3(x)\n",
    "        #x = F.relu(x)\n",
    "        x = F.relu(self.fc1(x.view(-1, 128)))\n",
    "        \n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #softmax to output probabilities:\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1952966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.7770670726895332\n",
      "10 1.22412571310997\n",
      "20 0.7379602491855621\n",
      "30 0.4467482455074787\n",
      "40 0.2879504356533289\n",
      "50 0.19443656923249364\n",
      "60 0.13585059391334653\n",
      "70 0.09854535688646138\n",
      "80 0.07396439835429192\n",
      "90 0.057191889150999486\n"
     ]
    }
   ],
   "source": [
    "#training first model:\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)\n",
    "\n",
    "#isolating the first picture\n",
    "first_input, first_output = train_input[:, 0:1], transform_to_one_hot(train_classes[:, 0])\n",
    "mu, std = first_input.mean(), first_input.std()\n",
    "first_input.sub_(mu).div_(std)\n",
    "\n",
    "#isolating the second picture\n",
    "second_input, second_output = train_input[:, 1:2], transform_to_one_hot(train_classes[:, 1])\n",
    "mu, std = second_input.mean(), second_input.std()\n",
    "second_input.sub_(mu).div_(std)\n",
    "\n",
    "#making a combined dataset:\n",
    "train_input = torch.cat((first_input, second_input), dim=0)\n",
    "train_output = torch.cat((first_output, second_output), dim=0)\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mu).div_(std)\n",
    "\n",
    "first_model = Net()\n",
    "\n",
    "\n",
    "train_model(first_model, train_input, train_output, 100, 100) #training on 1000\n",
    "#train_model(first_model, first_input, first_output, 100, 100) #training on 2000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d96032ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 1.1\n",
      "Test error: 6.1\n",
      "done :),\n"
     ]
    }
   ],
   "source": [
    "first_test_input, first_test_output = test_input[:, 0:1], transform_to_one_hot(test_classes[:, 0])\n",
    "#does normalizing the test input matter when already doing Batch norm?\n",
    "mu, std = first_test_input.mean(), first_test_input.std()\n",
    "first_test_input.sub_(mu).div_(std)\n",
    "\n",
    "print(\"Train error:\", compute_nb_errors(first_model, first_input, first_output, 20)/10)\n",
    "#first_model(first_input[0:1])\n",
    "print(\"Test error:\", compute_nb_errors(first_model, first_test_input, first_test_output, 20)/10)\n",
    "\n",
    "\n",
    "second_test_input, second_test_output = test_input[:, 1:2], transform_to_one_hot(test_classes[:, 1])\n",
    "#does normalizing the test input matter when already doing Batch norm?\n",
    "mu, std = second_test_input.mean(), second_test_input.std()\n",
    "second_test_input.sub_(mu).div_(std)\n",
    "\n",
    "print('done :),')\n",
    "\n",
    "#NOTE: the test results are highly irregular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a26786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is meant to be combined with the above network to first predict classes, \n",
    "# and then predict which one is bigger. Feed it the two prob dists\n",
    "class geqNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(20 , 2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        #self.fc2 = nn.Linear(40, 2)\n",
    "        #self.sig2 = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x.view(-1, 20))\n",
    "        x = self.sig1(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.sig2(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = self.sm(x)\n",
    "        return x\n",
    "    \n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72b44315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.24994432926178\n",
      "10 6.781591057777405\n",
      "20 6.465334713459015\n",
      "30 6.263695120811462\n",
      "40 6.128804266452789\n",
      "50 6.0326685309410095\n",
      "60 5.960366070270538\n",
      "70 5.903654098510742\n",
      "80 5.8577030301094055\n",
      "90 5.819515824317932\n"
     ]
    }
   ],
   "source": [
    "geq = geqNet()\n",
    "\n",
    "train_input = torch.detach(torch.cat((first_model(first_input), first_model(second_input)), dim=1))\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "\n",
    "train_output = torch.unsqueeze(train_target, 1)#.to(torch.float32)\n",
    "train_output_new = torch.zeros((len(train_output), 2))\n",
    "for i in range(len(train_output)):\n",
    "    train_output_new[i, train_output[i]]=1\n",
    "\n",
    "train_model(geq, train_input, train_output_new, 100, 100, criterion=torch.nn.BCEWithLogitsLoss())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36d170ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of errors: 159\n"
     ]
    }
   ],
   "source": [
    "#compute nb errors:\n",
    "output = geq(torch.detach(torch.cat((first_model(first_test_input), first_model(second_test_input)), dim=1)))\n",
    "nb=0\n",
    "for i in range(1000):\n",
    "    if output[i, 0]>output[i, 1]:\n",
    "        if test_target[i] == 1:\n",
    "            nb+=1\n",
    "    else:\n",
    "        if test_target[i] == 0: #\n",
    "            nb+=1\n",
    "print('nb of errors:', nb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "371ab799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0090, 0.0049, 0.0119, 0.0046, 0.0176, 0.0114, 0.0363, 0.0029, 0.8549,\n",
      "         0.0465],\n",
      "        [0.0351, 0.0282, 0.0511, 0.2064, 0.0085, 0.0235, 0.0057, 0.6307, 0.0045,\n",
      "         0.0062]], grad_fn=<SoftmaxBackward>) tensor([[0.0037, 0.0045, 0.0223, 0.0160, 0.0022, 0.0227, 0.0550, 0.0013, 0.8655,\n",
      "         0.0068],\n",
      "        [0.0074, 0.0252, 0.0049, 0.0058, 0.0107, 0.0028, 0.0018, 0.9330, 0.0019,\n",
      "         0.0064]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8, 8],\n",
      "        [3, 7]])\n",
      "tensor([1, 1])\n",
      "nb of errors: 327\n"
     ]
    }
   ],
   "source": [
    "#Testing is the hand crafted expectation works. It does not, is this a consequence of lack of idenpendence?  \n",
    "#Observation: 3 and 8 have a very very bad blablabla\n",
    "#####################################################\n",
    "def average(prob_vect):\n",
    "    avg=0\n",
    "    for i in range(10):\n",
    "        avg = i*prob_vect[i]\n",
    "    return avg\n",
    "#####################################################\n",
    "print(first_model(first_test_input[2:4]), first_model(second_test_input[2:4]))\n",
    "print(test_classes[2:4])\n",
    "print(test_target[2:4])\n",
    "\n",
    "#Hand made layer:\n",
    "output1 = first_model(first_test_input)\n",
    "output2 = first_model(second_test_input)\n",
    "\n",
    "nb=0\n",
    "for i in range(len(test_target)):\n",
    "    number1 = average(output1[i])\n",
    "    number2 = average(output2[i])\n",
    "    if number1-number2 > 0:\n",
    "        if test_target[i] == 1:\n",
    "            nb+=1\n",
    "    else:\n",
    "        if test_target[i] == 0:\n",
    "            nb+=1\n",
    "                \n",
    "print('nb of errors:', nb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ec7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are helper functions, should be in separate file\n",
    "######################################################################\n",
    "def transform_to_one_hot(train): #train is a 1 dimensional tensor and transorms to 2 dimensional\n",
    "    one_hot = torch.zeros((len(train), 10))\n",
    "    for i in range(len(train)):\n",
    "        one_hot[i, train[i]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 100, criterion=nn.MSELoss()):\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "        if e%10 == 0:\n",
    "            print(e, acc_loss)\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        #print(predicted_classes)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "######################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a50de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188373a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1dc5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################################################\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc1(x.view(-1, 128)))\n",
    "        print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81615ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb927a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1feb7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        nb_hidden = 100\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape) \n",
    "        x = self.conv1(x)\n",
    "        print(x.shape)\n",
    "        x = F.relu(F.max_pool2d(x, kernel_size=2))\n",
    "        print(x.shape)\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        #print('post conv2')\n",
    "        x = F.relu(F.max_pool2d(x, kernel_size=2))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x.view(-1, 64)))\n",
    "        #print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b6fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54538fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Any copyright is dedicated to the Public Domain.\n",
    "# https://creativecommons.org/publicdomain/zero/1.0/\n",
    "\n",
    "# Written by Francois Fleuret <francois@fleuret.org>\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import prologue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3eb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(500)\n",
    "######################################################################\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n",
    "######################################################################\n",
    "### Question 2: Number of testerrors\n",
    "\n",
    "for k in range(10):\n",
    "    model = Net(100)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38efad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284243bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "831a04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "#Weight sharing attempt. Siamese network\n",
    "\n",
    "######################################################################\n",
    "\n",
    "    \n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32,\n",
    "                               kernel_size = 4,\n",
    "                               padding = (4 - 1) // 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 128,\n",
    "                               kernel_size = 4)\n",
    "                               #padding = (4 - 1) // 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # self.fc1 = nn.Linear( 32 , 10)\n",
    "\n",
    "        #these are 4x4x8 + 4x4x8x32 +10x32 = 4 544 params (does tachnorm have param..?)\n",
    "        \n",
    "        #self.conv3 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        #self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear( 128 , 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        #self.finalLin = nn.Linear(20 , 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = torch.stack((F.max_pool2d(self.conv1(x[:, 0:1]), kernel_size=2), \n",
    "                        F.max_pool2d(self.conv1(x[:, 1:2]), kernel_size=2)), dim=1)\n",
    "        #print(x.shape)\n",
    "        x = torch.stack((self.bn1(x[:, 0]), self.bn1(x[:, 1])), dim=1)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.conv2(x)\n",
    "        x = torch.stack((F.max_pool2d(self.conv2(x[:, 0]), kernel_size=2), \n",
    "                        F.max_pool2d(self.conv2(x[:, 1]), kernel_size=2)), dim=1)\n",
    "        x = torch.stack((self.bn2(x[:, 0]), self.bn2(x[:, 1])), dim=1)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(x)\n",
    "        #x = F.max_pool2d(self.conv3(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        #x = self.bn3(x)\n",
    "        #x = F.relu(x)\n",
    "        x = torch.stack((F.relu(self.fc1(x[:, 0].view(-1, 128))), F.relu(self.fc1(x[:, 1].view(-1, 128)))), dim=1)\n",
    "        x = torch.stack((self.softmax(self.fc2(x[:, 0].view(-1, 128))), self.softmax(self.fc2(x[:, 1].view(-1, 128)))), dim=1)\n",
    "        \n",
    "        #x = self.sig1(x)\n",
    "        #print(x.shape)\n",
    "        #print(x.view(-1, 20).shape)\n",
    "        #x = self.finalLin(x.view(-1, 20)) #batch size!\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "######################################################################\n",
    "\n",
    "\n",
    "def big_transform_to_one_hot(train): #train is a??\n",
    "    one_hot = torch.zeros((len(train),2, 10))\n",
    "    for i in range(len(train)):\n",
    "        one_hot[i, 0, train[i, 0]] = 1\n",
    "        one_hot[i, 1, train[i, 1]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "140247f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9059951305389404\n",
      "10 0.7996836975216866\n",
      "20 0.6399395987391472\n",
      "30 0.5042908526957035\n",
      "40 0.3860178254544735\n",
      "50 0.2984176017343998\n",
      "60 0.23715350590646267\n",
      "70 0.19030438363552094\n",
      "80 0.1487573180347681\n",
      "90 0.11684594117105007\n"
     ]
    }
   ],
   "source": [
    "#training first model:\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)\n",
    "\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "first_input.sub_(mu).div_(std)\n",
    "\n",
    "\n",
    "first_model = SiameseNet()\n",
    "\n",
    "train_model(first_model, train_input, big_transform_to_one_hot(train_classes), 100, 100)\n",
    "#train_model(first_model, second_input, second_output, 100, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1f6f8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 8.2\n",
      "Test error: 15.2\n",
      "it worked!! :)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mu, std = test_input.mean(), test_input.std()\n",
    "first_test_input.sub_(mu).div_(std)\n",
    "\n",
    "print(\"Train error:\", compute_nb_errors(first_model, train_input, big_transform_to_one_hot(train_classes), 20)/10)\n",
    "#first_model(first_input[0:1])\n",
    "print(\"Test error:\", compute_nb_errors(first_model, test_input, big_transform_to_one_hot(test_classes), 20)/10)\n",
    "\n",
    "\n",
    "\n",
    "print('it worked!! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3552b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 100, criterion=nn.MSELoss()):\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "        if e%10 == 0:\n",
    "            print(e, acc_loss)\n",
    "            \n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        output1, output2 = output[:, 0], output[:, 1]\n",
    "        _, predicted_classes1 =  output1.max(1)\n",
    "        _, predicted_classes2 =  output2.max(1)\n",
    "        #print(predicted_classes)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, 0, predicted_classes1[k]] <= 0 or target[b + k, 1, predicted_classes2[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bedbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcfca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26326cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b394e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef81b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd85e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a34d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

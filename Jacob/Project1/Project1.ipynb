{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c2c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "import prologue\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4007fbf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prologue' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8f5bc022e3bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#just plotting a pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprologue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_pair_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# plot the first training sample pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prologue' is not defined"
     ]
    }
   ],
   "source": [
    "#just plotting a pair\n",
    "train_img, train_target, train_classes, test_img, test_target, test_classes = prologue.generate_pair_sets(1)\n",
    "# plot the first training sample pair\n",
    "print(train_img.shape)\n",
    "fig = plt.figure\n",
    "plt.imshow(train_img[0, 0], cmap='gray')\n",
    "plt.show() \n",
    "plt.imshow(train_img[0, 1], cmap='gray')\n",
    "plt.show() \n",
    "print(train_classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "158e1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following is training two models independently, \n",
    "# one per pair of digit, and on top of that to train another one \n",
    "# that predicts the class\n",
    "\n",
    "######################################################################\n",
    "\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32,\n",
    "                               kernel_size = 4,\n",
    "                               padding = (4 - 1) // 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 128,\n",
    "                               kernel_size = 4)\n",
    "                               #padding = (4 - 1) // 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # self.fc1 = nn.Linear( 32 , 10)\n",
    "\n",
    "        #these are 4x4x8 + 4x4x8x32 +10x32 = 4 544 params (does tachnorm have param..?)\n",
    "        \n",
    "        #self.conv3 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        #self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear( 128 , 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = F.max_pool2d(self.conv1(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        x = self.bn1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        #x = self.conv2(x)\n",
    "        x = F.max_pool2d(self.conv2(x), kernel_size=2)\n",
    "        x = self.bn2(x)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(x)\n",
    "        #x = F.max_pool2d(self.conv3(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        #x = self.bn3(x)\n",
    "        #x = F.relu(x)\n",
    "        x = F.relu(self.fc1(x.view(-1, 128)))\n",
    "        \n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #softmax to output probabilities:\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1952966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.7770670726895332\n",
      "10 1.22412571310997\n",
      "20 0.7379602491855621\n",
      "30 0.4467482455074787\n",
      "40 0.2879504356533289\n",
      "50 0.19443656923249364\n",
      "60 0.13585059391334653\n",
      "70 0.09854535688646138\n",
      "80 0.07396439835429192\n",
      "90 0.057191889150999486\n"
     ]
    }
   ],
   "source": [
    "#training first model:\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)\n",
    "\n",
    "#isolating the first picture\n",
    "first_input, first_output = train_input[:, 0:1], transform_to_one_hot(train_classes[:, 0])\n",
    "mu, std = first_input.mean(), first_input.std()\n",
    "first_input.sub_(mu).div_(std)\n",
    "\n",
    "#isolating the second picture\n",
    "second_input, second_output = train_input[:, 1:2], transform_to_one_hot(train_classes[:, 1])\n",
    "mu, std = second_input.mean(), second_input.std()\n",
    "second_input.sub_(mu).div_(std)\n",
    "\n",
    "#making a combined dataset:\n",
    "train_input = torch.cat((first_input, second_input), dim=0)\n",
    "train_output = torch.cat((first_output, second_output), dim=0)\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mu).div_(std)\n",
    "\n",
    "first_model = Net()\n",
    "\n",
    "\n",
    "train_model(first_model, train_input, train_output, 100, 100) #training on 1000\n",
    "#train_model(first_model, first_input, first_output, 100, 100) #training on 2000\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d96032ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 1.1\n",
      "Test error: 6.1\n",
      "done :),\n"
     ]
    }
   ],
   "source": [
    "first_test_input, first_test_output = test_input[:, 0:1], transform_to_one_hot(test_classes[:, 0])\n",
    "#does normalizing the test input matter when already doing Batch norm?\n",
    "mu, std = first_test_input.mean(), first_test_input.std()\n",
    "first_test_input.sub_(mu).div_(std)\n",
    "\n",
    "print(\"Train error:\", compute_nb_errors(first_model, first_input, first_output, 20)/10)\n",
    "#first_model(first_input[0:1])\n",
    "print(\"Test error:\", compute_nb_errors(first_model, first_test_input, first_test_output, 20)/10)\n",
    "\n",
    "\n",
    "second_test_input, second_test_output = test_input[:, 1:2], transform_to_one_hot(test_classes[:, 1])\n",
    "#does normalizing the test input matter when already doing Batch norm?\n",
    "mu, std = second_test_input.mean(), second_test_input.std()\n",
    "second_test_input.sub_(mu).div_(std)\n",
    "\n",
    "print('done :),')\n",
    "\n",
    "#NOTE: the test results are highly irregular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a26786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is meant to be combined with the above network to first predict classes, \n",
    "# and then predict which one is bigger. Feed it the two prob dists\n",
    "class geqNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(20 , 2)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        #self.fc2 = nn.Linear(40, 2)\n",
    "        #self.sig2 = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = self.fc1(x.view(-1, 20))\n",
    "        x = self.sig1(x)\n",
    "        #x = self.fc2(x)\n",
    "        #x = self.sig2(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = self.sm(x)\n",
    "        return x\n",
    "    \n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72b44315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.24994432926178\n",
      "10 6.781591057777405\n",
      "20 6.465334713459015\n",
      "30 6.263695120811462\n",
      "40 6.128804266452789\n",
      "50 6.0326685309410095\n",
      "60 5.960366070270538\n",
      "70 5.903654098510742\n",
      "80 5.8577030301094055\n",
      "90 5.819515824317932\n"
     ]
    }
   ],
   "source": [
    "geq = geqNet()\n",
    "\n",
    "train_input = torch.detach(torch.cat((first_model(first_input), first_model(second_input)), dim=1))\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "\n",
    "train_output = torch.unsqueeze(train_target, 1)#.to(torch.float32)\n",
    "train_output_new = torch.zeros((len(train_output), 2))\n",
    "for i in range(len(train_output)):\n",
    "    train_output_new[i, train_output[i]]=1\n",
    "\n",
    "train_model(geq, train_input, train_output_new, 100, 100, criterion=torch.nn.BCEWithLogitsLoss())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36d170ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of errors: 159\n"
     ]
    }
   ],
   "source": [
    "#compute nb errors:\n",
    "output = geq(torch.detach(torch.cat((first_model(first_test_input), first_model(second_test_input)), dim=1)))\n",
    "nb=0\n",
    "for i in range(1000):\n",
    "    if output[i, 0]>output[i, 1]:\n",
    "        if test_target[i] == 1:\n",
    "            nb+=1\n",
    "    else:\n",
    "        if test_target[i] == 0: #\n",
    "            nb+=1\n",
    "print('nb of errors:', nb)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "371ab799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0090, 0.0049, 0.0119, 0.0046, 0.0176, 0.0114, 0.0363, 0.0029, 0.8549,\n",
      "         0.0465],\n",
      "        [0.0351, 0.0282, 0.0511, 0.2064, 0.0085, 0.0235, 0.0057, 0.6307, 0.0045,\n",
      "         0.0062]], grad_fn=<SoftmaxBackward>) tensor([[0.0037, 0.0045, 0.0223, 0.0160, 0.0022, 0.0227, 0.0550, 0.0013, 0.8655,\n",
      "         0.0068],\n",
      "        [0.0074, 0.0252, 0.0049, 0.0058, 0.0107, 0.0028, 0.0018, 0.9330, 0.0019,\n",
      "         0.0064]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[8, 8],\n",
      "        [3, 7]])\n",
      "tensor([1, 1])\n",
      "nb of errors: 327\n"
     ]
    }
   ],
   "source": [
    "#Testing is the hand crafted expectation works. It does not, is this a consequence of lack of idenpendence?  \n",
    "#Observation: 3 and 8 have a very very bad blablabla\n",
    "#####################################################\n",
    "def average(prob_vect):\n",
    "    avg=0\n",
    "    for i in range(10):\n",
    "        avg = i*prob_vect[i]\n",
    "    return avg\n",
    "#####################################################\n",
    "print(first_model(first_test_input[2:4]), first_model(second_test_input[2:4]))\n",
    "print(test_classes[2:4])\n",
    "print(test_target[2:4])\n",
    "\n",
    "#Hand made layer:\n",
    "output1 = first_model(first_test_input)\n",
    "output2 = first_model(second_test_input)\n",
    "\n",
    "nb=0\n",
    "for i in range(len(test_target)):\n",
    "    number1 = average(output1[i])\n",
    "    number2 = average(output2[i])\n",
    "    if number1-number2 > 0:\n",
    "        if test_target[i] == 1:\n",
    "            nb+=1\n",
    "    else:\n",
    "        if test_target[i] == 0:\n",
    "            nb+=1\n",
    "                \n",
    "print('nb of errors:', nb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ec7301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are helper functions, should be in separate file\n",
    "######################################################################\n",
    "def transform_to_one_hot(train): #train is a 1 dimensional tensor and transorms to 2 dimensional\n",
    "    one_hot = torch.zeros((len(train), 10))\n",
    "    for i in range(len(train)):\n",
    "        one_hot[i, train[i]] = 1\n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 100, criterion=nn.MSELoss()):\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "        if e%10 == 0:\n",
    "            print(e, acc_loss)\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        #print(predicted_classes)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "######################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a50de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188373a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81615ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb927a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b6fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54538fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Any copyright is dedicated to the Public Domain.\n",
    "# https://creativecommons.org/publicdomain/zero/1.0/\n",
    "\n",
    "# Written by Francois Fleuret <francois@fleuret.org>\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import prologue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3eb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d9a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(500)\n",
    "######################################################################\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n",
    "######################################################################\n",
    "### Question 2: Number of testerrors\n",
    "\n",
    "for k in range(10):\n",
    "    model = Net(100)\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38efad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284243bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "831a04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "\n",
    "#Weight sharing attempt. Siamese network\n",
    "\n",
    "######################################################################\n",
    "\n",
    "    \n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32,\n",
    "                               kernel_size = 4,\n",
    "                               padding = (4 - 1) // 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 128,\n",
    "                               kernel_size = 4)\n",
    "                               #padding = (4 - 1) // 2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        # self.fc1 = nn.Linear( 32 , 10)\n",
    "\n",
    "        #these are 4x4x8 + 4x4x8x32 +10x32 = 4 544 params (does tachnorm have param..?)\n",
    "        \n",
    "        #self.conv3 = nn.Conv2d(64, 32, kernel_size=2)\n",
    "        #self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear( 128 , 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        #self.finalLin = nn.Linear(20 , 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        x = torch.stack((F.max_pool2d(self.conv1(x[:, 0:1]), kernel_size=2), \n",
    "                        F.max_pool2d(self.conv1(x[:, 1:2]), kernel_size=2)), dim=1)\n",
    "        #print(x.shape)\n",
    "        x = torch.stack((self.bn1(x[:, 0]), self.bn1(x[:, 1])), dim=1)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.conv2(x)\n",
    "        x = torch.stack((F.max_pool2d(self.conv2(x[:, 0]), kernel_size=2), \n",
    "                        F.max_pool2d(self.conv2(x[:, 1]), kernel_size=2)), dim=1)\n",
    "        x = torch.stack((self.bn2(x[:, 0]), self.bn2(x[:, 1])), dim=1)\n",
    "        #print(x.shape)\n",
    "        #x = F.relu(x)\n",
    "        #x = F.max_pool2d(self.conv3(x), kernel_size=2)\n",
    "        #print(x.shape)\n",
    "        #x = self.bn3(x)\n",
    "        #x = F.relu(x)\n",
    "        x = torch.stack((F.relu(self.fc1(x[:, 0].view(-1, 128))), F.relu(self.fc1(x[:, 1].view(-1, 128)))), dim=1)\n",
    "        x = torch.stack((self.softmax(self.fc2(x[:, 0].view(-1, 128))), self.softmax(self.fc2(x[:, 1].view(-1, 128)))), dim=1)\n",
    "        \n",
    "        #x = self.sig1(x)\n",
    "        #print(x.shape)\n",
    "        #print(x.view(-1, 20).shape)\n",
    "        #x = self.finalLin(x.view(-1, 20)) #batch size!\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "######################################################################\n",
    "\n",
    "\n",
    "def big_transform_to_one_hot(train): #train is a??\n",
    "    one_hot = torch.zeros((len(train),2, 10))\n",
    "    for i in range(len(train)):\n",
    "        one_hot[i, 0, train[i, 0]] = 1\n",
    "        one_hot[i, 1, train[i, 1]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140247f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8988799825310707\n",
      "10 0.773406982421875\n",
      "20 0.6200904995203018\n",
      "30 0.47546733543276787\n",
      "40 0.3675930052995682\n",
      "50 0.2942831963300705\n",
      "60 0.2282073125243187\n",
      "70 0.17376418318599463\n",
      "80 0.13541717734187841\n",
      "90 0.10892943385988474\n"
     ]
    }
   ],
   "source": [
    "#training first model:\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)\n",
    "\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mu).div_(std)\n",
    "\n",
    "first_model = SiameseNet()\n",
    "\n",
    "train_model(first_model, train_input, big_transform_to_one_hot(train_classes), 100, 100)\n",
    "#train_model(first_model, second_input, second_output, 100, 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1f6f8b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 7.4\n",
      "Test error: 15.1\n",
      "it worked!! :)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mu, std = test_input.mean(), test_input.std()\n",
    "test_input.sub_(mu).div_(std)\n",
    "\n",
    "print(\"Train error:\", compute_nb_errors(first_model, train_input, big_transform_to_one_hot(train_classes), 20)/10)\n",
    "#first_model(first_input[0:1])\n",
    "print(\"Test error:\", compute_nb_errors(first_model, test_input, big_transform_to_one_hot(test_classes), 20)/10)\n",
    "\n",
    "\n",
    "\n",
    "print('it worked!! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3552b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, nb_epochs = 100, criterion=nn.MSELoss()):\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        acc_loss = 0\n",
    "\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "        if e%10 == 0:\n",
    "            print(e, acc_loss)\n",
    "            \n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        output1, output2 = output[:, 0], output[:, 1]\n",
    "        _, predicted_classes1 =  output1.max(1)\n",
    "        _, predicted_classes2 =  output2.max(1)\n",
    "        #print(predicted_classes)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k, 0, predicted_classes1[k]] <= 0 or target[b + k, 1, predicted_classes2[k]] <= 0:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bedbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5afcfca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SiameseNet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26326cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = SiameseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20b394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8938411623239517\n",
      "10 0.7547252401709557\n",
      "20 0.627328559756279\n",
      "30 0.4917127452790737\n",
      "40 0.3789517432451248\n",
      "50 0.2846033647656441\n",
      "60 0.212232930585742\n",
      "70 0.160043403506279\n",
      "80 0.12555128056555986\n",
      "90 0.10193012375384569\n"
     ]
    }
   ],
   "source": [
    "Net.train_model(train_input, big_transform_to_one_hot(train_classes), 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ef81b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.compute_nb_errors(test_input, big_transform_to_one_hot(test_classes), 25)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cd85e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a34d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

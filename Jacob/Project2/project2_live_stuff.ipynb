{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec33423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x10ddc6220>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import prologue as prologue\n",
    "import framework\n",
    "\n",
    "\n",
    "torch.set_grad_enabled(True) #By the end we should have this set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f27f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block we discuss put all the external functions, \n",
    "# namely generate_disc, computing number of errors, and training the model.\n",
    "# We should not need to change any of this.\n",
    "\n",
    "######################################################################\n",
    "######################### DATA things ################################\n",
    "######################################################################\n",
    "def generate_disc_set(nb): # This can be kept the same\n",
    "    input = torch.empty(nb, 2).uniform_(-1, 1)\n",
    "    target = input.pow(2).sum(1).sub(2 / math.pi).sign().add(1).div(2).long()\n",
    "    return input, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(100)\n",
    "test_input, test_target = generate_disc_set(100)\n",
    "\n",
    "# center the data:\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std)\n",
    "\n",
    "mini_batch_size = 1\n",
    "\n",
    "######################################################################\n",
    "######################### ERROR things ################################\n",
    "######################################################################\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target): #this can be kept the same\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors\n",
    "\n",
    "\n",
    "######################################################################\n",
    "######################### TRAIN things ################################\n",
    "######################################################################\n",
    "# The following should be modified\n",
    "\n",
    "def train_model(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss() #replace this by self macde MSE\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1) #replace this by self made SGD for MSE\n",
    "    nb_epochs = 10\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad() # replace this so it works with \n",
    "            loss.backward() # replace this to self made backard method\n",
    "            optimizer.step() # '_'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f36184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the network\n",
    "Net = framework.Linear(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63954823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.4522,  0.0526, -0.3339],\n",
       "         [ 0.6499,  0.2892, -0.5368]]),\n",
       " tensor([0.6768, 0.5370])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the parameters for sanity check\n",
    "Net.param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3dffc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2325, 0.1548])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the forward method\n",
    "Net.forward(torch.tensor([1.0, 2.0, 3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ae8b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1977, -0.2366,  0.2029])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the backward method\n",
    "Net.backward(torch.tensor([1.0, -1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15752ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.],\n",
       "        [-1., -2., -3.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the weight accum\n",
    "Net.weights_grad_accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fa021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we try the ReLu\n",
    "rel = framework.ReLu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f13ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel.forward(Net.weights_grad_accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756966ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel.backward(Net.weights_grad_accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7080ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we try the Sequential\n",
    "seq = framework.Sequential((framework.Linear(3, 2), framework.ReLu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d828bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([-1.1681,  0.9413])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.9413])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.forward(torch.tensor([1.0, 2.0, 3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb55cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1., -1.])\n",
      "tensor([-0.1469, -0.2029, -0.4310])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.backward(torch.tensor([1.0, -1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b82a8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below this line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e92fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem Set 3:\n",
    "#/usr/bin/env python\n",
    "\n",
    "# Any copyright is dedicated to the Public Domain.\n",
    "# https://creativecommons.org/publicdomain/zero/1.0/\n",
    "\n",
    "# Written by Francois Fleuret <francois@fleuret.org>\n",
    "\n",
    "\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def sigma(x):\n",
    "    return x.tanh()\n",
    "\n",
    "def dsigma(x):\n",
    "    return 4 * (x.exp() + x.mul(-1).exp()).pow(-2)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def loss(v, t): #This is MSE, right?\n",
    "    return (v - t).pow(2).sum()\n",
    "\n",
    "def dloss(v, t):\n",
    "    return 2 * (v - t)\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def forward_pass(w1, b1, w2, b2, x):\n",
    "    x0 = x\n",
    "    s1 = w1.mv(x0) + b1\n",
    "    x1 = sigma(s1)\n",
    "    s2 = w2.mv(x1) + b2\n",
    "    x2 = sigma(s2)\n",
    "\n",
    "    return x0, s1, x1, s2, x2\n",
    "\n",
    "#whose arguments correspond to the networkâ€™s parameters, \n",
    "#the target vector, the quantities computed by the forward pass, \n",
    "#and the tensors used to store the cumulated sums of the gradient \n",
    "#on individual samples, and updates the latters according to the\n",
    "#formula of the backward pass.\n",
    "\n",
    "def backward_pass(w1, b1, w2, b2, #current weights and biases of the network\n",
    "                  t, # target vector\n",
    "                  x, s1, x1, s2, x2, #output of network\n",
    "                  dl_dw1, dl_db1, dl_dw2, dl_db2): #tensors used to stor the sumulated sums of the gradient\n",
    "    x0 = x\n",
    "    dl_dx2 = dloss(x2, t)\n",
    "    dl_ds2 = dsigma(s2) * dl_dx2\n",
    "    dl_dx1 = w2.t().mv(dl_ds2)\n",
    "    dl_ds1 = dsigma(s1) * dl_dx1\n",
    "\n",
    "    dl_dw2.add_(dl_ds2.view(-1, 1).mm(x1.view(1, -1)))\n",
    "    dl_db2.add_(dl_ds2)\n",
    "    dl_dw1.add_(dl_ds1.view(-1, 1).mm(x0.view(1, -1)))\n",
    "    dl_db1.add_(dl_ds1)\n",
    "\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4c4aa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1673c8443e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnb_train_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.90\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "nb_classes = train_target.size(1)\n",
    "nb_train_samples = train_input.size(0)\n",
    "\n",
    "zeta = 0.90\n",
    "\n",
    "train_target = train_target * zeta\n",
    "test_target = test_target * zeta\n",
    "\n",
    "nb_hidden = 50\n",
    "eta = 1e-1 / nb_train_samples\n",
    "epsilon = 1e-6\n",
    "\n",
    "w1 = torch.empty(nb_hidden, train_input.size(1)).normal_(0, epsilon)\n",
    "b1 = torch.empty(nb_hidden).normal_(0, epsilon)\n",
    "w2 = torch.empty(nb_classes, nb_hidden).normal_(0, epsilon)\n",
    "b2 = torch.empty(nb_classes).normal_(0, epsilon)\n",
    "\n",
    "dl_dw1 = torch.empty(w1.size())\n",
    "dl_db1 = torch.empty(b1.size())\n",
    "dl_dw2 = torch.empty(w2.size())\n",
    "dl_db2 = torch.empty(b2.size())\n",
    "\n",
    "for k in range(1000):\n",
    "\n",
    "    # Back-prop\n",
    "\n",
    "    acc_loss = 0\n",
    "    nb_train_errors = 0\n",
    "\n",
    "    dl_dw1.zero_()\n",
    "    dl_db1.zero_()\n",
    "    dl_dw2.zero_()\n",
    "    dl_db2.zero_()\n",
    "\n",
    "    for n in range(nb_train_samples):\n",
    "        x0, s1, x1, s2, x2 = forward_pass(w1, b1, w2, b2, train_input[n])\n",
    "\n",
    "        pred = x2.max(0)[1].item()\n",
    "        if train_target[n, pred] < 0.5: nb_train_errors = nb_train_errors + 1\n",
    "        acc_loss = acc_loss + loss(x2, train_target[n])\n",
    "\n",
    "        backward_pass(w1, b1, w2, b2,\n",
    "                      train_target[n],\n",
    "                      x0, s1, x1, s2, x2,\n",
    "                      dl_dw1, dl_db1, dl_dw2, dl_db2)\n",
    "\n",
    "    # Gradient step\n",
    "\n",
    "    w1 = w1 - eta * dl_dw1\n",
    "    b1 = b1 - eta * dl_db1\n",
    "    w2 = w2 - eta * dl_dw2\n",
    "    b2 = b2 - eta * dl_db2\n",
    "\n",
    "    # Test error\n",
    "\n",
    "    nb_test_errors = 0\n",
    "\n",
    "    for n in range(test_input.size(0)):\n",
    "        _, _, _, _, x2 = forward_pass(w1, b1, w2, b2, test_input[n])\n",
    "\n",
    "        pred = x2.max(0)[1].item()\n",
    "        if test_target[n, pred] < 0.5: nb_test_errors = nb_test_errors + 1\n",
    "\n",
    "    print('{:d} acc_train_loss {:.02f} acc_train_error {:.02f}% test_error {:.02f}%'\n",
    "          .format(k,\n",
    "                  acc_loss,\n",
    "                  (100 * nb_train_errors) / train_input.size(0),\n",
    "                  (100 * nb_test_errors) / test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b5dff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std create_shallow_model -1.000000 train_error 1.00% test_error 0.50%\n",
      "std create_deep_model -1.000000 train_error 8.50% test_error 8.90%\n",
      "std create_shallow_model 0.001000 train_error 1.40% test_error 1.60%\n",
      "std create_deep_model 0.001000 train_error 49.60% test_error 50.00%\n",
      "std create_shallow_model 0.010000 train_error 0.70% test_error 1.40%\n",
      "std create_deep_model 0.010000 train_error 49.60% test_error 50.00%\n",
      "std create_shallow_model 0.100000 train_error 1.00% test_error 0.50%\n",
      "std create_deep_model 0.100000 train_error 50.40% test_error 50.00%\n",
      "std create_shallow_model 1.000000 train_error 0.80% test_error 0.50%\n",
      "std create_deep_model 1.000000 train_error 50.40% test_error 50.00%\n",
      "std create_shallow_model 10.000000 train_error 0.60% test_error 0.80%\n",
      "std create_deep_model 10.000000 train_error 50.40% test_error 50.00%\n"
     ]
    }
   ],
   "source": [
    "torch.set_grad_enabled(True) #At the end, this should be set to False\n",
    "\n",
    "#Pb set 5:\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# Any copyright is dedicated to the Public Domain.\n",
    "# https://creativecommons.org/publicdomain/zero/1.0/\n",
    "\n",
    "# Written by Francois Fleuret <francois@fleuret.org>\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def generate_disc_set(nb):\n",
    "    input = torch.empty(nb, 2).uniform_(-1, 1)\n",
    "    target = input.pow(2).sum(1).sub(2 / math.pi).sign().add(1).div(2).long()\n",
    "    return input, target\n",
    "\n",
    "#train_input, train_target = generate_disc_set(1000)\n",
    "#test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std)\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def train_model(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss() #replace this by self macde MSE\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1) #replace this by self made SGD for MSE\n",
    "    nb_epochs = 250\n",
    "\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad() # replace this so it works with \n",
    "            loss.backward() # replace this to self made backard method\n",
    "            optimizer.step() # '_'\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target): #this s\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def create_shallow_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )\n",
    "\n",
    "def create_deep_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )\n",
    "\n",
    "######################################################################\n",
    "\n",
    "for std in [ -1, 1e-3, 1e-2, 1e-1, 1e-0, 1e1 ]:\n",
    "\n",
    "    for m in [ create_shallow_model, create_deep_model ]:\n",
    "\n",
    "        model = m()\n",
    "\n",
    "        if std > 0:\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p.normal_(0, std)\n",
    "\n",
    "        train_model(model, train_input, train_target)\n",
    "\n",
    "        print('std {:s} {:f} train_error {:.02f}% test_error {:.02f}%'.format(\n",
    "            m.__name__,\n",
    "            std,\n",
    "            compute_nb_errors(model, train_input, train_target) / train_input.size(0) * 100,\n",
    "            compute_nb_errors(model, test_input, test_target) / test_input.size(0) * 100\n",
    "        )\n",
    "        )\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e123e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
